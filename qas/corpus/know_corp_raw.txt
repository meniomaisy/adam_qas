['The Linux kernel is an open-source monolithic Unix-like computer operating system kernel. The Linux family of operating systems is based on this kernel and deployed on both traditional computer systems such as personal computers and servers, usually in the form of Linux distributions, and on various embedded devices such as routers, wireless access points, PBXes, set-top boxes, FTA receivers, smart TVs, PVRs, and NAS appliances. The Android operating system for tablet computers, smartphones, and smartwatches uses services provided by the Linux kernel to implement its functionality. While the adoption on desktop computers is low, Linux-based operating systems dominate nearly every other segment of computing, from mobile devices to mainframes. As of November 2017, all of the world\'s 500 most powerful supercomputers run Linux.\nThe Linux kernel was conceived and created in 1991 by Linus Torvalds for his personal computer and with no cross-platform intentions, but has since expanded to support a huge array of computer architectures, many more than other operating systems or kernels. Linux rapidly attracted developers and users who adopted it as the kernel for other free software projects, notably the GNU Operating System. The Linux kernel has received contributions from nearly 12,000 programmers from more than 1,200 companies, including some of the largest software and hardware vendors.\nThe Linux kernel API, the application programming interface (API) through which user programs interact with the kernel, is meant to be very stable and to not break userspace programs (some programs, such as those with GUIs, rely on other APIs as well). As part of the kernel\'s functionality, device drivers control the hardware; "mainlined" device drivers are also meant to be very stable. However, the interface between the kernel and loadable kernel modules (LKMs), unlike in many other kernels and operating systems, is not meant to be very stable by design.\nThe Linux kernel, developed by contributors worldwide, is a prominent example of free and open source software, and it\'s supported up to six years depending on version. Day-to-day development discussions take place on the Linux kernel mailing list (LKML). The Linux kernel is released under the GNU General Public License version 2 (GPLv2), with some firmware images released under various non-free licenses.\n\n\n== History ==\n\nIn April 1991, Linus Torvalds, at the time a 21-year-old computer science student at the University of Helsinki, Finland, started working on some simple ideas for an operating system. He started with a task switcher in Intel 80386 assembly language and a terminal driver. On 25 August 1991, Torvalds posted the following to comp.os.minix, a newsgroup on Usenet:\n\nI\'m doing a (free) operating system (just a hobby, won\'t be big and professional like gnu) for 386(486) AT clones. This has been brewing since April, and is starting to get ready. I\'d like any feedback on things people like/dislike in minix, as my OS resembles it somewhat (same physical layout of the file-system (due to practical reasons) among other things).\nI\'ve currently ported bash(1.08) and gcc(1.40), and things seem to work. This implies that I\'ll get something practical within a few months [...] Yes - it\'s free of any minix code, and it has a multi-threaded fs. It is NOT portable (uses 386 task switching etc), and it probably never will support anything other than AT-harddisks, as that\'s all I have :-(.\n[...] It\'s mostly in C, but most people wouldn\'t call what I write C. It uses every conceivable feature of the 386 I could find, as it was also a project to teach me about the 386. As already mentioned, it uses a MMU, for both paging (not to disk yet) and segmentation. It\'s the segmentation that makes it REALLY 386 dependent (every task has a 64Mb segment for code & data - max 64 tasks in 4Gb. Anybody who needs more than 64Mb/task - tough cookies). [...] Some of my "C"-files (specifically mm.c) are almost as much assembler as C. [...] Unlike minix, I also happen to LIKE interrupts, so interrupts are handled without trying to hide the reason behind them.\n\nAfter that, many people contributed code to the project. Early on, the MINIX community contributed code and ideas to the Linux kernel. At the time, the GNU Project had created many of the components required for a free operating system, but its own kernel, GNU Hurd, was incomplete and unavailable. The BSD operating system had not yet freed itself from legal encumbrances. Despite the limited functionality of the early versions, Linux rapidly gained developers and users.\nBy September 1991, version 0.01 of the Linux kernel was released on the FTP server (ftp.funet.fi) of the Finnish University and Research Network (FUNET). It had 10,239 lines of code. In October 1991, version 0.02 of the Linux kernel was released.\nIn December 1991, Linux kernel 0.11 was released. This version was the first to be self-hosted as Linux kernel 0.11 could be compiled by a computer running the same kernel version. When Torvalds released version 0.12 in February 1992, he adopted the GNU General Public License (GPL) over his previous self-drafted license, which had not permitted commercial redistribution.\nOn 19 January 1992, the first post to the new newsgroup alt.os.linux was submitted. On 31 March 1992, the newsgroup was renamed comp.os.linux.\nThe X Window System was ported to Linux, so that in March 1992, Linux version 0.95 was the first to be capable of running X. This large jump in version numbers, from 0.1x to 0.9x, resulted from the expectation that version 1.0, without major missing pieces, was imminent. However, this proved to be wrong and from 1993 to early 1994, 15 development versions of version 0.99 appeared.\nOn 14 March 1994, Linux kernel 1.0.0 was released, with 176,250 lines of code. In March 1995, Linux kernel 1.2.0 was released, with 310,950 lines of code.\nVersion 2 of the Linux kernel, released on 9 June 1996, was followed by additional major versions under the version 2 header:\n25 January 1999 – release of Linux kernel 2.2.0 (1,800,847 lines of code)\n18 December 1999 – IBM mainframe patches for 2.2.13 were published, allowing Linux kernel to be used on enterprise-class machines\n4 January 2001 – release of Linux kernel 2.4.0 (3,377,902 lines of code)\n17 December 2003 – release of Linux kernel 2.6.0 (5,929,913 lines of code)\nStarting in 2004, the release process changed and new kernels started coming out on a regular schedule every 2–3 months, numbered 2.6.0, 2.6.1, up through 2.6.39.\nOn 21 July 2011, Torvalds announced the release of Linux kernel 3.0: "Gone are the 2.6.<bignum> days". The version bump is not about major technological changes when compared to Linux 2.6.39; it marks the kernel\'s 20th anniversary. The time-based release process remained the same.\nVersion 3.10 of the Linux kernel, released in June 2013, contains 15,803,499 lines of code, while the version 4.1, released in June 2015, has grown to over 19.5 million lines of code contributed by almost 14,000 programmers.\n\n\n=== Tanenbaum–Torvalds debate ===\n\nThe fact that Linux is a monolithic kernel rather than a microkernel was the topic of a debate between Andrew S. Tanenbaum, the creator of MINIX, and Linus Torvalds. The debate, started in 1992 on the Usenet discussion group comp.os.minix, was about Linux and kernel architecture in general. Tanenbaum argued that microkernels were superior to monolithic kernels and that therefore Linux was obsolete. Unlike traditional monolithic kernels, device drivers in Linux are easily configured as loadable kernel modules and are loaded or unloaded while running the system. This subject was revisited on 9 May 2006, and on 12 May 2006 Tanenbaum wrote a position statement.\n\n\n=== Popularity ===\nThe huge rise in popularity of the Android operating system, which includes the Linux kernel, has made the kernel the most popular choice for mobile devices, rivaling the installed base of all other operating systems. Including previous years, three billion Android smartphones were estimated to have been sold by the end of 2014.\nMany consumer routers also use the Linux kernel, as well as a wide variety of other embedded devices, such as smart TVs, set-top boxes, and webcams. Many desktop Linux distributions including the Linux kernel exist, but the usage share of Linux distributions is low in comparison to other operating systems.\n\n\n== Legal aspects ==\n\n\n=== Licensing terms ===\nInitially, Torvalds released Linux under a license which forbade any commercial use. This was changed in version 0.12 by a switch to the GNU General Public License (GPL). This license allows distribution and sale of possibly modified and unmodified versions of Linux but requires that all those copies be released under the same license and be accompanied by the complete corresponding source code.\nTorvalds has described licensing Linux under the GPL as the "best thing I ever did".\n\n\n==== GPL version 3 ====\nThe Linux kernel is licensed explicitly only under version 2 of the GPL, without offering the licensee the option to choose "any later version", which is a common GPL extension. There was considerable debate about how easily the license could be changed to use later GPL versions (including version 3), and whether this change is even desirable. Torvalds himself specifically indicated upon the release of version 2.4.0 that his own code is released only under version 2. However, the terms of the GPL state that if no version is specified, then any version may be used, and Alan Cox pointed out that very few other Linux contributors had specified a particular version of the GPL.\nIn September 2006, a survey of 29 key kernel programmers indicated that 28 preferred GPLv2 to the then-current GPLv3 draft. Torvalds commented, "I think a number of outsiders... believed that I personally was just the odd man out, because I\'ve been so publicly not a huge fan of the GPLv3." This group of high-profile kernel developers, including Linus Torvalds, Greg Kroah-Hartman and Andrew Morton, commented on mass media about their objections to the GPLv3. They referred to clauses regarding DRM/tivoization, patents, "additional restrictions" and warned a Balkanisation of the "Open Source Universe" by the GPLv3. Linus Torvalds, who decided not to adopt the GPLv3 for the Linux kernel, reiterated his criticism even years later.\n\n\n=== Loadable kernel modules ===\nIt is debated whether loadable kernel modules (LKMs) are to be considered derivative works under copyright law, and thereby fall under the terms of the GPL.\nTorvalds has stated his belief that LKMs using only a limited, "public" subset of the kernel interfaces can sometimes be non-derived works, thus allowing some binary-only drivers and other LKMs that are not licensed under the GPL. A very good example for this is the usage of dma_buf by the proprietary Nvidia graphics drivers. dma_buf is a recent kernel feature (like the rest of the kernel, it is licensed under the GPL) that allows multiple GPUs to quickly copy data into each other\'s framebuffers. One possible use case would be Nvidia Optimus that pairs a fast GPU with an Intel integrated GPU, where the Nvidia GPU writes into the Intel framebuffer when it is active. But, Nvidia cannot use this infrastructure because it uses a technical means to enforce the rule that it can only be used by LKMs that are also GPL. Alan Cox replied on LKML, rejecting a request from one of their engineers to remove this technical enforcement from the API. Not all Linux kernel contributors agree with this interpretation, however, and even Torvalds agrees that many LKMs are clearly derived works, and indeed he writes that "kernel modules ARE derivative \'by default\'".\nOn the other hand, Torvalds has also said that "one gray area in particular is something like a driver that was originally written for another operating system (i.e. clearly not a derived work of Linux in origin). [...] THAT is a gray area, and _that_ is the area where I personally believe that some modules may be considered to not be derived works simply because they weren\'t designed for Linux and don\'t depend on any special Linux behaviour." Proprietary graphics drivers, in particular, are heavily discussed. Ultimately, it is likely that such questions can only be resolved by a court.\n\n\n=== Firmware binary blobs ===\nOne point of licensing controversy is the use of firmware "binary blobs" in Linux kernel to support several hardware devices. These files are under a variety of licenses, out of which many are restrictive and their exact underlying source code is usually unknown.\nIn 2002, Richard Stallman stated why, in his point of view, such blobs make the Linux kernel partially non-free software, and that distributing Linux kernel "violates the GPL", which requires "complete corresponding source code" to be available. In 2008, Free Software Foundation Latin America started Linux-libre as a project that creates a completely free variant of the Linux kernel without proprietary objects; it is used by certain completely free Linux distributions, such as those endorsed by the Free Software Foundation, while it can also be used on most distributions.\nOn 15 December 2010, the Debian Project announced that the next Debian stable version "6.0 Squeeze" would come with a kernel "stripped of all non-free firmware bits". This policy was continued to be applied in later stable Debian releases.\n\n\n=== Trademark ===\n\nLinux is a registered trademark of Linus Torvalds in the United States and some other countries. This is the result of an incident in which William Della Croce, Jr., who was not involved in the Linux project, trademarked the name and subsequently demanded royalties for its use. Several Linux backers retained legal counsel and filed suit against Della Croce. The issue was settled in August 1997 when the trademark was assigned to Linus Torvalds.\n\n\n=== SCO litigation ===\n\nIn early 2007, SCO filed the specific details of the purported copyright infringement. Despite previous claims that SCO was the rightful owner of 1 million lines of code, they specified 326 lines of code, most of which were uncopyrightable. In August 2007, the court in the Novell case ruled that SCO did not actually own the Unix copyrights, to begin with, though the Tenth Circuit Court of Appeals ruled in August 2009 that the question of who owned the copyright properly remained for a jury to answer. The jury case was decided on 30 March 2010 in Novell\'s favour.\n\n\n== Architecture ==\n\nThe Linux kernel is a monolithic kernel, supporting true preemptive multitasking (both in user mode and, since the 2.6 series, in kernel mode), virtual memory, shared libraries, demand loading, shared copy-on-write executables (via KSM), memory management, the Internet protocol suite, and threading.\nDevice drivers and kernel extensions run in kernel space (ring 0 in many CPU architectures), with full access to the hardware, although some exceptions run in user space, for example, filesystems based on FUSE/CUSE, and parts of UIO. The graphics system most people use with Linux does not run within the kernel. Unlike standard monolithic kernels, device drivers are easily configured as modules, and loaded or unloaded while the system is running. Also, unlike standard monolithic kernels, device drivers can be pre-empted under certain conditions; this feature was added to handle hardware interrupts correctly and to better support symmetric multiprocessing. By choice, the Linux kernel has no binary kernel interface.\nThe hardware is also incorporated into the file hierarchy. Device drivers interface to user applications via an entry in the /dev or /sys directories. Process information as well is mapped to the file system through the /proc directory.\n\n\n=== Programming language ===\nThe Linux kernel is written in the version of the C programming language supported by GCC (which has introduced a number of extensions and changes to standard C), together with a number of short sections of code written in the assembly language (in GCC\'s "AT&T-style" syntax) of the target architecture. Because of the extensions to C it supports, GCC was for a long time the only compiler capable of correctly building the Linux kernel.\n\n\n=== Compiler compatibility ===\nGCC is the default compiler for the Linux kernel source. In 2004, Intel claimed to have modified the kernel so that its C compiler was also capable of compiling it. There was another such reported success in 2009, with a modified 2.6.22 version of the kernel.\nSince 2010, effort has been underway to build the Linux kernel with Clang, an alternative compiler for the C language; as of 12 April 2014, the official kernel could almost be compiled by Clang. The project dedicated to this effort is named LLVMLinux after the LLVM compiler infrastructure upon which Clang is built. LLVMLinux does not aim to fork either the Linux kernel or the LLVM, therefore it is a meta-project composed of patches that are eventually submitted to the upstream projects. By enabling the Linux kernel to be compiled by Clang that, among other advantages, is known for faster compilation compared with GCC, kernel developers may benefit from a faster workflow due to shorter compilation times.\n\n\n=== Interfaces ===\n\nConformance to standards is a general policy for the Linux kernel\'s internals. Another rule is that a kernel component is not accepted into the Linux kernel mainline if there is only proprietary user-space software using that component.\n\n\n==== Kernel-to-userspace API ====\n\nSource code portability ensures that a C program written by conforming to a standard can be successfully compiled and run on any system that also conforms to the same standard. The relevant standards, aiming to achieve source code portability of programs, that the development of the Linux kernel, the GNU C Library, and associated utilities tries to adhere to, are POSIX and the Single UNIX Specification.\nThe Linux kernel API of the Linux kernel, representing the kernel\'s system call interface, is composed of the available system calls.\n\n\n==== Kernel-to-userspace ABI ====\n\nBinary portability shall guarantee that any program once compiled for a given hardware platform, can be run in its compiled form on any other hardware platform that conforms to the standard. Binary portability is an essential requirement for the commercial viability of independent software vendor (ISV) applications built for the operating systems based on the Linux kernel. Binary compatibility is much more demanding than source code portability; as of February 2014, the only standard concerning itself with binary compatibility is the Linux Standard Base (LSB).\n\n\n==== In-kernel API ====\nThere are a couple of kernel internal APIs utilized between the different subsystems and subsystems of subsystems. Some of them have been kept stable over several releases, others have not. There are no guarantees regarding the in-kernel APIs. Maintainers and contributors are free to augment or change them at any time.\nExamples of in-kernel APIs include software frameworks/APIs for the following classes of device drivers:\nVideo4Linux –  for video capture hardware\nAdvanced Linux Sound Architecture (ALSA) –  for sound cards\nNew API –  for network interface controllers\nDirect Rendering Manager –  for graphics accelerators\nKMS driver –  for display controllers\nmac80211 –  for wireless network interface controllers\nWEXT –  for wireless network interface controllers (obsolete).\n\n\n==== In-kernel ABI ====\nSome organizations have strongly supported defining and maintaining of a stable in-kernel ABI over several releases. For example, it would benefit hardware manufacturers which release proprietary kernel modules and distribute binary-only software (e.g. device drivers). However, the Linux kernel developers choose not to maintain a stable in-kernel ABI. This allows Linux kernel development to happen much more quickly.\n\n\n=== Technical features ===\n\n\n==== Preemption ====\n\nThe Linux kernel provides preemptive scheduling under certain conditions. Until kernel version 2.4, only user processes were preemptive, i.e., in addition to time quantum expiration, an execution of current process in user mode would be interrupted if higher dynamic priority processes entered TASK_RUNNING state. Toward 2.6 series of the Linux kernel, an ability to interrupt a task executing kernel code was added, although with that not all sections of the kernel code can be preempted.\nThe Linux kernel contains different scheduler classes. By default the kernel uses a scheduler mechanism called the Completely Fair Scheduler introduced in the 2.6.23 version of the kernel. Internally this default-scheduler class is also known as SCHED_OTHER, but the kernel also contains two POSIX-compliant real-time scheduling classes named SCHED_FIFO (realtime first-in-first-out) and SCHED_RR (realtime round-robin), both of which take precedence over the default class.\nThrough the use of the real-time Linux kernel patch PREEMPT_RT, support for full preemption of critical sections, interrupt handlers, and "interrupt disable" code sequences can be supported. Partial mainline integration of the real-time Linux kernel patch already brought some functionality to the kernel mainline. Preemption improves latency, increases responsiveness, and makes Linux more suitable for desktop and real-time applications. Older versions of the kernel had a so-called big kernel lock for synchronization across the entire kernel, which was finally removed by Arnd Bergmann in 2011.\nAdditional scheduling policy known as SCHED_DEADLINE, implementing the earliest deadline first algorithm (EDF), was added in kernel version 3.14, released on 30 March 2014.\n\n\n==== Portability ====\n\nWhile not originally designed to be portable, Linux is now one of the most widely ported operating system kernels, running on a diverse range of systems from the ARM architecture to IBM z/Architecture mainframe computers. The first port beyond Linux\'s original 386 architecture was performed on the Motorola 68000 platform by Amiga users, who accomplished this by replacing major parts of the kernel. The modifications to the kernel were so fundamental that Torvalds viewed the Motorola version as a fork and a "Linux-like operating system" rather than as an actual port. It was, however, the impetus that Torvalds needed to lead a major restructure of the kernel code to facilitate porting to competing computing architectures. The first Linux endorsed port was to the DEC Alpha AXP 64-bit platform which was demonstrated at DECUS in May, 1995m supporting both 386 and Alpha in a single source tree. DEC was responsible for supplying the hardware necessary to Torvalds to enable a port of Linux to 64 bits that same year.\nLinux runs as the main operating system on IBM\'s Blue Gene and other fastest supercomputers, including the top Chinese one. As of November 2017, all of the world\'s 500 fastest supercomputers run some variant of Linux. Linux has also been ported to various handheld devices such as Apple\'s iPod and iPhone. Some operating systems developed for mobile phones use modified versions of the Linux kernel, including Google Android, Firefox OS, HP webOS, Nokia Maemo and Jolla Sailfish OS.\n\n\n==== Kernel panic and oopses ====\n\nIn Linux, a "panic" is an unrecoverable system error detected by the kernel, as opposed to similar errors detected by user space code. It is possible for kernel code to indicate such a condition by calling the panic function located in the header file sys/system.h. However, most panics are the result of unhandled processor exceptions in kernel code, such as references to invalid memory addresses. These are typically indicative of a bug somewhere in the call chain leading to the panic. They can also indicate a failure of hardware, such as a failed RAM cell or errors in arithmetic functions in the processor caused by a processor bug, overheating/damaged processor, or a soft error.\nA report of a non-fatal bug in the kernel is called an "oops"; such deviations from correct behavior of the Linux kernel may allow continued operation with compromised reliability. These crash reports are automatically collected and can be sent upstream by various software, such as kerneloops, ABRT (Fedora) and apport (Ubuntu). KernelOops.org collects these reports and publishes statistics on their website.\nThe kernel panic message might not be printed visibly in some conditions, such as when using a graphical desktop. To debug such conditions, other methods such as attaching a serial port console can be used.\n\n\n==== Live patching ====\nRebootless updates can even be applied to the kernel by using live patching technologies such as Ksplice, kpatch and kGraft. Minimalistic foundations for live kernel patching were merged into the Linux kernel mainline in kernel version 4.0, which was released on 12 April 2015. Those foundations, known as livepatch and based primarily on the kernel\'s ftrace functionality, form a common core capable of supporting hot patching by both kGraft and kpatch, by providing an application programming interface (API) for kernel modules that contain hot patches and an application binary interface (ABI) for the userspace management utilities. However, the common core included into Linux kernel 4.0 supports only the x86 architecture and does not provide any mechanisms for ensuring function-level consistency while the hot patches are applied. As of April 2015, there is ongoing work on porting kpatch and kGraft to the common live patching core provided by the Linux kernel mainline.\n\n\n=== Security ===\nComputer security is a much-publicized topic in relation to the Linux kernel because a large portion of the kernel bugs present potential security flaws. For example, they may allow for privilege escalation or create denial-of-service attack vectors. Over the years, numerous such flaws were found and fixed in the Linux kernel. New security features are frequently implemented to improve the Linux kernel\'s security.\nCritics have accused kernel developers of covering up security flaws or at least not announcing them; in 2008, Linus Torvalds responded to this with the following:\n\nI personally consider security bugs to be just "normal bugs". I don\'t cover them up, but I also don\'t have any reason what-so-ever to think it\'s a good idea to track them and announce them as something special...one reason I refuse to bother with the whole security circus is that I think it glorifies—and thus encourages—the wrong behavior. It makes "heroes" out of security people, as if the people who don\'t just fix normal bugs aren\'t as important. In fact, all the boring normal bugs are way more important, just because there\'s a lot more of them. I don\'t think some spectacular security hole should be glorified or cared about as being any more "special" than a random spectacular crash due to bad locking.\n\nLinux distributions typically release security updates to fix vulnerabilities in the Linux kernel. Many offer long-term support releases that receive security updates for a certain Linux kernel version for an extended period of time.\n\n\n=== Feature history ===\nVersion 1.0 of the Linux kernel was released on 14 March 1994. This release of the Linux kernel only supported single-processor i386-based computer systems. Portability became a concern, and so version 1.2 (released 7 March 1995) gained support for computer systems using processors based on the Alpha, SPARC, and MIPS architectures.\nVersion 2.0 was released on 9 June 1996. The series included 41 releases. The major feature of 2.0 was support for symmetric multiprocessing (SMP) and support for more types of processors.\nVersion 2.2, released on 20 January 1999, removed the global spinlock and provided improved SMP support, added support for the m68k and PowerPC architectures, and added new file systems (including read-only support for Microsoft\'s NTFS).\nVersion 2.4.0, released on 4 January 2001, contained support for ISA Plug and Play, USB, and PC Cards. It also included support for the PA-RISC processor from Hewlett-Packard. Development for 2.4.x changed a bit in that more features were made available throughout the duration of the series, including support for Bluetooth, Logical Volume Manager (LVM) version 1, RAID support, InterMezzo and ext3 file systems.\nVersion 2.6.0 was released on 17 December 2003. The development for 2.6.x changed further towards including new features throughout the duration of the series. Among the changes that have been made in the 2.6 series are: integration of µClinux into the mainline kernel sources, PAE support, support for several new lines of CPUs, integration of Advanced Linux Sound Architecture (ALSA) into the mainline kernel sources, support for up to 232 users (up from 216), support for up to 229 process IDs (64-bit only, 32-bit arches still limited to 215), substantially increased the number of device types and the number of devices of each type, improved 64-bit support, support for file systems which support file sizes of up to 16 terabytes, in-kernel preemption, support for the Native POSIX Thread Library (NPTL), User-mode Linux integration into the mainline kernel sources, SELinux integration into the mainline kernel sources, InfiniBand support, and considerably more. Also notable are the addition of several file systems throughout the 2.6.x releases: FUSE, JFS, XFS, ext4 and more. Details on the history of the 2.6 kernel series can be found in the ChangeLog files on the 2.6 kernel series source code release area of kernel.org.\nVersion 3.0 was released on 22 July 2011. On 30 May 2011, Torvalds announced that the big change was "NOTHING. Absolutely nothing." and asked, "...let\'s make sure we really make the next release not just an all new shiny number, but a good kernel too." After the expected 6–7 weeks of the development process, it would be released near the 20th anniversary of Linux.\nIn December 2012, Torvalds decided to reduce kernel complexity by removing support for i386 processors, making the 3.7 kernel series the last one still supporting the original processor. The same series unified support for the ARM processor.\nVersion 3.11, released on 2 September 2013, adds many new features such as new O_TMPFILE flag for open(2) to reduce temporary file vulnerabilities, experimental AMD Radeon dynamic power management, low-latency network polling, and zswap (compressed swap cache).\nThe numbering change from 2.6.39 to 3.0, and from 3.19 to 4.0, involved no meaningful technical differentiation. The major version number was increased to avoid large minor numbers.\n\n\n== Development ==\n\n\n=== Developer community ===\nAs of 2007, the development of the kernel had shifted from the top 20 most active developers writing 80% of the code to the top 30 writing 30% of the code, with top developers spending more time reviewing changes. Developers can also be categorized by affiliation; in 2007, the top category was unknown while the top corporation was Red Hat with 12% of contributions, and known amateurs at 3.9%. The kernel changes made in year 2007 have been submitted by over 1900 developers, which may be a significant underestimate because developers working in teams usually count as one. It is generally assumed that the community of Linux kernel developers comprises 5000 or 6000 members.\nUpdate from the 2016 Linux Kernel Development Report, issued by the Linux Foundation, covering the period from 3.18 (December 2014) to 4.7 (July 2016): About 1500 developers are contributing to each release from about 200-250 companies on average per release. The top 30 developers contributed a little more than 16% of the code. As of companies, the top contributors are Intel (12.9%) and Red Hat (8.0%), the third and fourth places are held by the \'none\' (7.7%) and \'unknown\' (6.8%) categories.\n\n\n=== Development process ===\nA developer who wants to change the Linux kernel starts with developing and testing that change. Depending on how significant the change is and how many subsystems it modifies that change will either consist of a single patch or of multiple patches. In case of a single subsystem that is maintained by a single maintainer, these patches are sent as e-mails to the maintainer of the subsystem with the appropriate mailing list in Cc. The maintainer and the readers of the mailing list will review the patches and provide feedback. Once the review process has finished the maintainer accepts the patches in his kernel tree. If these changes are bug fixes that are considered important enough a pull request that includes the patches will be sent to Linus within a few days. Otherwise, a pull request will be sent to Linus during the next merge window. The merge window usually lasts two weeks and starts immediately after the release of the previous kernel version.\nLinus Torvalds has the last word not only over which changes get accepted into the Linux kernel but also over who can become a maintainer. Kernel maintainers keep their role unless they give their role up voluntarily. There are no known examples of kernel maintainers who have been told to step down. Additionally, there are no known examples of a kernel maintainer having been criticized for the style of her or his interactions with developers by Linus. This gives maintainers a significant amount of power. Although the culture in the kernel development community has improved over the years, the kernel development community has a reputation of sometimes being rough. Developers who feel treated unfairly can report this to the Linux Foundation\'s Technical Advisory Board. Some kernel community members disagree with the current discussion culture.\n\n\n=== Development community conflicts ===\nProminent Linux kernel developers are aware that it is important to avoid conflicts between developers. There is no code of conduct for kernel developers since Linus Torvalds does not agree with having such a code. However, a code of conflict exists.\nThere have been several notable conflicts among Linux kernel developers. Examples of such conflicts are:\nOn 10 July 2007 Con Kolivas announced that he would cease developing for the Linux kernel. Discussing his reasons in an interview, he expressed frustration with aspects of the mainline kernel development process, which he felt did not give sufficient priority to desktop interactivity, in addition to hacking taking a toll on his health, work and family..\nOn 28 July 2009 Alan Cox quit his role as the TTY layer maintainer after disagreement with Torvalds about the scope of work required to fix an error in that subsystem.\nIn December 2010 there was a discussion between Linux SCSI maintainer James Bottomley and SCST maintainer Vladislav Bolkhovitin about which SCSI target stack should be included in the Linux kernel - SCST or LIO. Although at that time SCST was considered technically superior, LIO was merged upstream. This made some Linux users upset.\nOn 14 June 2012 Linus Torvalds made it very clear that he did not agree with NVIDIA releasing its drivers as closed source drivers.\nOn 6 October 2014 Lennart Poettering accused Linus Torvalds of tolerating the rough discussion style on Linux kernel related mailing lists and of being a bad role model.\nOn 5 March 2015 Christoph Hellwig filed a lawsuit against VMware for infringement of the copyright on the Linux kernel. Linus Torvalds made it clear that he did not agree with this and similar initiatives by calling lawyers a festering disease .\nOn 5 October 2015 Sage Sharp (formerly Sarah Sharp) announced to quit the Linux kernel community because she felt that she was technically but not personally respected, citing toxic behavior in the Linux kernel community.\n\n\n=== Codebase ===\nAs of 2013, the 3.10 release of the Linux kernel had 15,803,499 lines of code. As of 2007, roughly 5% of the code is part of the "core" while 52% is drivers.\n\nInstead of a roadmap, there are technical guidelines. Instead of a central resource allocation, there are persons and companies who all have a stake in the further development of the Linux kernel, quite independently from one another: People like Linus Torvalds and I don’t plan the kernel evolution. We don’t sit there and think up the roadmap for the next two years, then assign resources to the various new features. That\'s because we don’t have any resources. The resources are all owned by the various corporations who use and contribute to Linux, as well as by the various independent contributors out there. It\'s those people who own the resources who decide...\n\nLinux is evolution, not intelligent design!\n\nBy this statement it is meant that evolution often does odd (and "sub-optimal") things exactly because it does incremental changes which do not break at any point. As a result, any released version of the Linux kernel is fully usable, even if, for example, device drivers do not support all features of the hardware they are written for.\nThe conceptual architecture of the Linux kernel has proved its success, while essential factors for this success were the provision for the organization of developers, and the provision for system extensibility. The Linux kernel\'s architecture was required to support many independent volunteer developers, which suggested that the system portions that require the most development\u200d—\u200chardware device drivers, file systems, and network protocols\u200d—\u200cbe implemented in an extensible fashion. The Linux kernel\'s architecture chose to make these systems extensible using a data abstraction technique –  each hardware device driver is implemented as a separate module that supports a common interface. In this way, a single developer can add a new device driver, with minimal interaction required with other developers of the Linux kernel.\nAnother important extension to the Linux kernel is the addition of more supported hardware platforms. The architecture of the system supports this extensibility by separating all hardware-specific code into distinct modules within each subsystem. In this way, a small group of developers can implement a port of the Linux kernel to a new hardware architecture by re-implementing only the machine-specific portions of the kernel.\n\n\n=== Estimated cost to redevelop ===\n\nThe cost to redevelop the Linux kernel version 2.6.0 in a traditional proprietary development setting has been estimated to be US$612 million (€467M, £394M) in 2004 prices using the COCOMO man-month estimation model. In 2006, a study funded by the European Union put the redevelopment cost of kernel version 2.6.8 higher, at €882M ($1.14bn, £744M).\nThis topic was revisited in October 2008 by Amanda McPherson, Brian Proffitt, and Ron Hale-Evans. Using David A. Wheeler\'s methodology, they estimated redevelopment of the 2.6.25 kernel now costs $1.3bn (part of a total $10.8bn to redevelop Fedora 9). Again, Garcia-Garcia and Alonso de Magdaleno from University of Oviedo (Spain) estimate that the value annually added to kernel was about €100M between 2005 and 2007 and €225M in 2008, it would cost also more than €1bn (about $1.4bn as of February 2010) to develop in the European Union.\nAs of 7 March 2011, using then-current LOC (lines of code) of a 2.6.x Linux kernel and wage numbers with David A. Wheeler\'s calculations it would cost approximately $3bn (about €2.2bn) to redevelop the Linux kernel as it keeps getting bigger.\n\n\n=== Development model ===\nAs of 2015, in the current development scheme, the main branch of development is not a traditional "stable" branch; instead, it incorporates all kinds of changes, including both the latest features, and security and bug fixes. For users who do not want to risk updating to new versions containing code that may not be well tested, a separate set of "stable" branches exist, one for each released version, which are meant for people who just want the security and bug fixes, but not a whole new version. These branches are maintained by the stable team (Greg Kroah-Hartman, Chris Wright, and others).\nThe development model for the 2.6 kernel series was significantly different compared to the 2.5 series. Before the 2.6 series, there was a stable branch (2.4) where only relatively minor and safe changes were merged, and an unstable branch (2.5), where bigger changes and cleanups were allowed. Both of these branches had been maintained by the same set of people, led by Torvalds. This meant that users would always have a well-tested 2.4 version with the latest security and bug fixes to use, though they would have to wait for the features which went into the 2.5 branch. The downside of this was that the "stable" kernel ended up so far behind that it no longer supported recent hardware and lacked needed features. In the late 2.5 kernel series, some maintainers elected to try backporting of their changes to the stable kernel series, which resulted in bugs being introduced into the 2.4 kernel series. The 2.5 branch was then eventually declared stable and renamed to 2.6. But instead of opening an unstable 2.7 branch, the kernel developers decided to continue putting major changes into the 2.6 branch, which would then be released at a pace faster than 2.4.x but slower than 2.5.x. This had the desirable effect of making new features more quickly available and getting more testing of the new code, which was added in smaller batches and easier to test.\nAs a response to the lack of a stable kernel tree where people could coordinate the collection of bug fixes as such, in December 2005 Adrian Bunk announced that he would keep releasing 2.6.16.y kernels when the stable team moved on to 2.6.17. He also included some driver updates, making the maintenance of the 2.6.16 series very similar to the old rules for maintenance of a stable series such as 2.4. Since then, the "stable team" had been formed, and it would keep updating kernel versions with bug fixes. In October 2008 Adrian Bunk announced that he will maintain 2.6.27 for a few years as a replacement of 2.6.16. The stable team picked up on the idea and as of 2010 they continue to maintain that version and release bug fixes for it, in addition to others.\nAfter the change of the development model with 2.6.x, developers continued to want what one might call an unstable kernel tree, one that changes as rapidly as new patches come in. Andrew Morton decided to repurpose his -mm tree from memory management to serve as the destination for all new and experimental code. In September 2007, Morton decided to stop maintaining this tree. In February 2008, Stephen Rothwell created the linux-next tree to serve as a place where patches aimed to be merged during the next development cycle are gathered. Several subsystem maintainers also adopted the suffix -next for trees containing code which is meant to be submitted for inclusion in the next release cycle.\nAs of January 2014, the in-development version of the Linux kernel is held in an unstable branch named linux-next.\n\n\n==== Relation with Linux distributions ====\nMost Linux users run a kernel supplied by their Linux distribution. Some distributions ship the "vanilla" or "stable" kernels. However, several Linux distribution vendors (such as Red Hat and Debian) maintain another set of Linux kernel branches which are integrated into their products. These are usually updated at a slower pace compared to the "vanilla" branch, and they usually include all fixes from the relevant "stable" branch, but at the same time they can also add support for drivers or features which had not been released in the "vanilla" version the distribution vendor started basing their branch from.\n\n\n=== Maintenance ===\nWhile Linus Torvalds supervises code changes and releases to the latest kernel versions, he has delegated the maintenance of older versions to other programmers. Major releases as old as 2.0 (officially made obsolete with the kernel 2.2.0 release in January 1999) are maintained as needed, although at a very slow pace.\nLinux kernel 4.14 has been released and with it long-term support (LTS) increased to 6 year, intending to provide longer support period for Android devices.\n\n\n==== Releases before 2.6.0 ====\n\n\n==== 2.6.x.y releases ====\nVersions 2.6.16 and 2.6.27 of the Linux kernel were unofficially supported in a long-term support (LTS) fashion, before a 2011 working group in the Linux Foundation started a formal long-term support initiative.\n\n\n==== 3.x.y releases ====\n\n\n==== 4.x.y releases ====\n\n\n=== Revision control ===\nThe Linux kernel source code used to be maintained without the help of an automated source code management system, mostly because of Linus Torvalds\' dislike of centralized SCM systems.\nIn 2002, Linux kernel development switched to BitKeeper, an SCM system which satisfied Torvalds\' technical requirements. BitKeeper was made available to Linus and several others free of charge but was not free software, which was a source of controversy. The system did provide some interoperability with free SCM systems such as CVS and Subversion.\nIn April 2005 efforts to reverse-engineer, the BitKeeper system by Andrew Tridgell led BitMover, the company which maintained BitKeeper, to stop supporting the Linux development community. In response, Torvalds and others wrote a new source code control system for the purpose, called Git. The new system was written within weeks, and in two months the first official kernel release was made using Git. Git soon developed into a separate project in its own right and gained widespread adoption.\n\n\n=== Version numbering ===\nLinux kernel development has used three different version numbering schemes.\nThe first scheme was used in the run-up to version 1.0. The first version of the kernel was 0.01. This was followed by 0.02, 0.03, 0.10, 0.11, 0.12 (the first GPL version), 0.95, 0.96, 0.97, 0.98, 0.99 and then 1.0. From 0.95 on there were many patch releases between versions.\nAfter the 1.0 release and prior to version 2.6, the number was composed as "a.b.c", where the number "a" denoted the kernel version, the number "b" denoted the major revision of the kernel, and the number "c" indicated the minor revision of the kernel. The kernel version was changed only when major changes in the code and the concept of the kernel occurred, twice in the history of the kernel: in 1994 (version 1.0) and in 1996 (version 2.0). Version 3.0 was released in 2011, but it was not a major change in kernel concept. The major revision was assigned according to the even–odd version numbering scheme. The minor revision had been changed whenever security patches, bug fixes, new features or drivers were implemented in the kernel.\nIn 2004, after version 2.6.0 was released, the kernel developers held several discussions regarding the release and version scheme and ultimately Linus Torvalds and others decided that a much shorter "time-based" release cycle would be beneficial. For about seven years, the first two numbers remained "2.6", and the third number was incremented with each new release, which rolled out after two to three months. A fourth number was sometimes added to account for bug and security fixes (only) to the kernel version. The even-odd system of alternation between stable and unstable was gone. Instead, development pre-releases are titled release candidates, which is indicated by appending the suffix \'-rc\' to the kernel version, followed by an ordinal number.\nThe first use of the fourth number occurred when a grave error, which required immediate fixing, was encountered in 2.6.8\'s NFS code. However, there were not enough other changes to legitimize the release of a new minor revision (which would have been 2.6.9). So, 2.6.8.1 was released, with the only change being the fix of that error. With 2.6.11, this was adopted as the new official versioning policy. Later it became customary to continuously back-port major bug-fixes and security patches to released kernels and indicate that by updating the fourth number.\nOn 29 May 2011, Linus Torvalds announced that the kernel version would be bumped to 3.0 for the release following 2.6.39, due to the minor version number getting too large and to commemorate the 20th anniversary of Linux. It continued the time-based release practice introduced with 2.6.0, but using the second number; for example, 3.1 would follow 3.0 after a few months. An additional number (now the third number) would be added on when necessary to designate security and bug fixes, as for example with 3.0.18; the Linux community refers to this as "x.y.z" versioning. The major version number was also later raised to 4, for the release following version 3.19.\nIn addition to Torvalds\' -rc development releases, the version number was sometimes suffixed with letter sequences, such as tip, which were at times the initials of a software developer, indicating another development branch. For example, ck stands for Con Kolivas and ac stands for Alan Cox. Sometimes, the letters are related to the primary development area of the branch the kernel is built from, for example, wl indicates a wireless networking test build. Also, distributors may have their own suffixes with different numbering systems and for back-ports to their enterprise (i.e. stable but older) distribution versions.\n\n\n=== Timeline ===\n\n\n=== Variants ===\nThere are certain variants of the Linux kernel that provide additional functionality but do not belong to the Linux kernel mainline. Such variants of the Linux kernel include Linux-libre, Compute Node Linux, Cooperative Linux, Longene, grsecurity, INK, L4Linux, MkLinux, RTLinux, and User-mode Linux. Some of these variants have been partially merged into the mainline.\n\n\n== See also ==\n\nComparison of operating system kernels\n\n\n== Notes ==\n\n\n== References ==\n\n\n== Further reading ==\n\n\n== External links ==\nOfficial website\nLinux kernel documentation index\nLinux kernel man pages\nKernel bugzilla, and regressions for each recent kernel version\n\nKernel Newbies, a source of various kernel-related information\nLinGrok, a Linux kernel source code cross-reference\nGreg Kroah Hartman on the Linux kernel on YouTube']
['The Linux kernel provides several interfaces to user-space applications that are used for different purposes and that have different properties by design. There are two types of application programming interface (API) in the Linux kernel that are not to be confused: the "kernel–user space" API and the "kernel internal" API.\n\n\n== Linux API ==\n\nThe Linux API is the kernel–user space API, which allows programs in user space to access system resources and services of the Linux kernel. It is composed out of the System Call Interface of the Linux kernel and the subroutines in the GNU C Library (glibc). The focus of the development of the Linux API has been to provide the usable features of the specifications defined in POSIX in a way which is reasonably compatible, robust and performant, and to provide additional useful features not defined in POSIX, just as the kernel–user space APIs of other systems implementing the POSIX API also provide additional features not defined in POSIX.\nThe Linux API, by choice, has been kept stable over the decades and never breaks; this stability guarantees the portability of source code. At the same time, Linux kernel developers have historically been conservative and meticulous about introducing new system calls.\nMuch available free and open-source software is written for the POSIX API. Since so much more development flows into the Linux kernel as compared to the other POSIX-compliant combinations of kernel and C standard library, the Linux kernel and its API have been augmented with additional features. As far as these additional features provide a technical advantage, programming for the Linux API is preferred over the POSIX-API. Well-known current examples are udev, systemd and Weston. People such as Lennart Poettering openly advocate to prefer the Linux API over the POSIX API, where this offers advantages.\nAt FOSDEM 2016, Michael Kerrisk explained some of the perceived issues with the Linux kernel\'s user-space API, describing that it contains multiple design errors by being non-extensible, unmaintainable, overly complex, of limited purpose, in violation of standards, and inconsistent. Most of those mistakes cannot be fixed because doing so would break the ABI that the kernel presents to the user space.\n\n\n=== System Call Interface of the Linux kernel ===\nSystem Call Interface is the denomination for the entirety of all implemented and available system calls in a kernel. Various subsystems, such as e.g. the DRM define their own system calls and the entirety is called System Call Interface.\nVarious issues with the organization of the Linux kernel system calls are being publicly discussed. Issues have been pointed out by Andy Lutomirski, Michael Kerrisk and others.\n\n\n=== The C standard library ===\n\nThe GNU C Library is a wrapper around the system calls of the Linux kernel; the combination of the Linux kernel System Call Interface and glibc is what builds the Linux API.\nGNU C Library (glibc)\nEmbedded GLIBC\nuClibc\nklibc\nNewlib\nmusl\ndietlibc\nlibbionic and libhybris\n\n\n==== Additions to POSIX ====\nAs in other Unix-like systems, additional capabilities of the Linux kernel exist that are not part of POSIX:\ncgroups subsystem, the system calls it introduces and libcgroup\nThe system calls of the Direct Rendering Manager, especially the driver-private ioctls for the command submission are not part of the POSIX specifications.\nAdvanced Linux Sound Architecture could set system calls, which are not part of the POSIX specifications\nThe system calls futex (fast userspace mutex), epoll, splice, dnotify, fanotify, and inotify have been exclusive to the Linux kernel so far.\nThe system call getrandom was introduced in version 3.17 of the Linux kernel mainline\nmemfd was proposed by the kdbus developersmemfd_create was merged into the Linux kernel mainline in kernel version 3.17\n\nreadahead initiates a file "read-ahead" into page cache\nDRM has been paramount for the development and implementations of well-defined and performant free and open-source graphics device drivers without which no rendering acceleration would be available at all, or even worse, only the 2D drivers would be available in the X.Org Server. DRM was developed for Linux, and since has been ported to other operating systems as well.\n\n\n=== Further libraries ===\nlibdrm (for Direct Rendering Manager)\nlibnl (The libnl suite is a collection of libraries providing APIs to netlink protocol based Linux kernel interfaces.)\nlibevdev (for evdev)\nlibasound (Advanced Linux Sound Architecture)\n…\n\n\n== Linux ABI ==\n\nThe term Linux ABI refers to a kernel–user space ABI. The Application binary interface refers to the compiled binaries, in machine code. Any such ABI is therefore bound to the instruction set. Defining a useful ABI and keeping it stable is less the responsibility of the Linux kernel developers or of the developers of the GNU C Library, and more the task for Linux distributions and Independent software vendor (ISVs) who wish to sell and provide support for their proprietary software as binaries only for such a single Linux ABI, as opposed to supporting multiple Linux ABIs.\nIn the Wikipedia a category is maintained for articles on Category:Proprietary software for Linux.\nAn ABI has to be defined for every instruction set, such as x86, x86-64, MIPS, ARMv7-A (32-Bit), ARMv8-A (64-Bit), etc. with the endianness, if both are supported.\nIt should be able to compile the software with different compilers against the definitions specified in the ABI and achieve full binary compatibility. Compilers that are free and open-source software are e.g. GNU Compiler Collection, LLVM/Clang.\nEnd-users are in fact not all interested in the Linux API (or the Windows API), but in the ABIs.\n\n\n== In–kernel APIs ==\nThere are a lot of kernel-internal APIs for all the subsystems to interface with one another. These are being kept fairly stable, but there is no guarantee for stability. In case new research or insights make a change seem favorable, an API is changed, all necessary rewrite and testing have to be done by the author.\nThe Linux kernel is a monolithic kernel, hence device drivers are kernel components. To ease the burden of companies maintaining their (proprietary) device drivers out-of-tree, stable APIs for the device drivers have been repeatedly requested. The Linux kernel developers have repeatedly denied guaranteeing stable in-kernel APIs for device drivers. Guaranteeing such would have faltered the development of the Linux kernel in the past and would still in the future and, due to the nature of free and open-source software, are not necessary. Ergo, by choice, the Linux kernel has no stable in-kernel API.\n\n\n== In–kernel ABIs ==\nSince there are no stable in–kernel APIs, there cannot be stable in–kernel ABIs.\n\n\n== Abstraction APIs ==\n\nFor several use cases the Linux API is considered too low-level and higher abstraction APIs are used. Such of course still need to work on top of the low-level Linux APIs. Examples:\nimplementation of the OpenGL and Vulkan specifications in proprietary Linux graphics drivers and the free and open-source implementation in Mesa\nimplementation of the OpenAL specification\nSimple DirectMedia Layer: abstraction API for input/sound/etc. available for many operating systems\nSimple and Fast Multimedia Library: like above\n\n\n== See also ==\n\nThe Linux Programming Interface by Michael Kerrisk\nSemaphore (programming)\nsystem call –  is a function to facilitate programs to request services from the kernel\neventfd()\nnetlink –  socket family used for IPC between kernel and user space processes, designed as the successor of ioctl; Netlink was added by Alan Cox during Linux kernel 1.3 development as a character driver interface to provide multiple kernel and user-space bidirectional communications links. Then, Alexey Kuznetsov extended it during Linux kernel 2.1 development to provide a flexible and extensible messaging interface to the new advanced routing infrastructure. Since then, Netlink sockets have become one of the main interfaces that kernel subsystems provide to user-space applications in Linux. Modern WNIC drivers use it to communicate with user-space.\n\nWindows API –  article on various API available on Microsoft Windows operating systems\nwindows.h –  header file for the C programming language which contains declarations for all of the functions in the Windows API\n\nWine –  a compatibility layer between Linux and programs written for Microsoft Windows\nlibhybris – compatibility layer between Linux and programs written for Android\n\n\n== References ==\n\n\n== External links ==\nThe API of Linux kernel 2.6.20 – sadly no current version available\nThe Linux Programming Interface\nInteractive Linux kernel map with main API functions and structures\nLinux Device Drivers by Jonathan Corbet, Greg Kroah-Hartman and Alessandro Rubini, 3rd edition\nLinux Kernel Linked List Explained\nTLPI: API changes, Linux API changes since The Linux Programming Interface was released in 2010']
['Kernel-based Virtual Machine (KVM) is a virtualization infrastructure for the Linux kernel that turns it into a hypervisor. It was merged into the Linux kernel mainline in kernel version 2.6.20, which was released on February 5, 2007. KVM requires a processor with hardware virtualization extensions. KVM has also been ported to FreeBSD and illumos in the form of loadable kernel modules.\nKVM originally supported x86 processors and has been ported to S/390, PowerPC, and IA-64. An ARM port was merged during the 3.9 kernel merge window.\nA wide variety of guest operating systems work with KVM, including many flavours and versions of Linux, BSD, Solaris, Windows, Haiku, ReactOS, Plan 9, AROS Research Operating System and OS X. In addition, Android 2.2, GNU/Hurd (Debian K16), Minix 3.1.2a, Solaris 10 U3 and Darwin 8.0.1, together with other operating systems and some newer versions of these listed, are known to work with certain limitations.\nParavirtualization support for certain devices is available for Linux, OpenBSD, FreeBSD, NetBSD, Plan 9 and Windows guests using the VirtIO API. This supports a paravirtual Ethernet card, a paravirtual disk I/O controller, a balloon device for adjusting guest memory usage, and a VGA graphics interface using SPICE or VMware drivers.\n\n\n== Internals ==\n\nBy itself, KVM does not perform any emulation. Instead, it exposes the /dev/kvm interface, which a userspace host can then use to:\nSet up the guest VM\'s address space. The host must also supply a firmware image (usually a custom BIOS when emulating PCs) that the guest can use to bootstrap into its main OS.\nFeed the guest simulated I/O.\nMap the guest\'s video display back onto the system host.\nOn Linux, QEMU versions 0.10.1 and later is one such userspace host. QEMU uses KVM when available to virtualize guests at near-native speeds, but otherwise falls back to software-only emulation.\nInternally, KVM uses SeaBIOS as an open source implementation of a 16-bit x86 BIOS.\n\n\n== Licensing ==\nKVM\'s parts are licensed under various GNU licenses:\nKVM kernel module: GPL v2\nKVM user module: LGPL v2\nQEMU virtual CPU core library (libqemu.a) and QEMU PC system emulator: LGPL\nLinux user mode QEMU emulator: GPL\nBIOS files (bios.bin, vgabios.bin and vgabios-cirrus.bin): LGPL v2 or later\n\n\n== History ==\nAvi Kivity began the development of KVM at Qumranet, a technology startup company that was acquired by Red Hat in 2008.\nKVM was merged into the Linux kernel mainline in kernel version 2.6.20, which was released on 5 February 2007.\nKVM is maintained by Paolo Bonzini.\n\n\n== Graphical management tools ==\n\nKimchi –  web-based virtualization management tool for KVM\nVirtual Machine Manager –  supports creating, editing, starting, and stopping KVM-based virtual machines, as well as live or cold drag-and-drop migration of VMs between hosts.\nProxmox Virtual Environment –  an open-source virtualization management package including KVM and LXC. It has a bare-metal installer, a web-based remote management GUI, a HA cluster stack, unified storage, flexible network, and optional commercial support.\nOpenQRM –  management platform for managing heterogeneous data center infrastructures.\nGNOME Boxes –  Gnome interface for managing libvirt guests on Linux.\noVirt –  open-source virtualization management tool for KVM built on top of libvirt\n\n\n== Emulated hardware ==\n\n\n== See also ==\n\n\n== References ==\n\n\n== Bibliography ==\nAmit Shah (2016-11-02). "Ten years of KVM". lwn.net. Retrieved 2017-02-10. \n\n\n== External links ==\nOfficial website\nBest practices for the Kernel-based Virtual Machine, IBM, second edition, April 2012\nVirtio-blk Performance Improvement, KVM Forum 2012, November 8, 2012, by Asias He\nWikibook QEMU & KVM']
['Windows NT 4.0 is a preemptively multitasked graphical operating system, designed to work with either uniprocessor or symmetric multi-processor computers. It was part of Microsoft\'s Windows NT family of operating systems and was released to manufacturing on 31 July 1996. It is a 32-bit operating system available in both workstation and server editions with a graphical environment similar to that of Windows 95.\n\n\n== Overview ==\nThe successor to Windows NT 3.51, Windows NT 4.0 introduced the user interface of Windows 95 to the Windows NT family, including the Windows shell, File Explorer (known as Windows NT Explorer at the time), and the use of "My" nomenclature for shell folders (e.g. My Computer). It also includes most components introduced with Windows 95. Internally, Windows NT 4.0 was known as the Shell Update Release (SUR). While many administrative tools, notably User Manager for Domains, Server Manager and Domain Name Service Manager still used the old graphical user interfaces, the Start menu in Windows NT 4.0 separated the per-user shortcuts and folders from the shared shortcuts and folders by a separator line. Windows NT 4.0 includes some enhancements from Microsoft Plus! for Windows 95 such as the Space Cadet pinball table, font smoothing, showing window contents while dragging, high-color icons and stretching the wallpaper to fit the screen. Windows Desktop Update could also be installed on Windows NT 4.0 to update the shell version and install Task Scheduler. Windows NT 4.0 Resource Kit included the Desktop Themes utility.\nWindows NT 4.0 is the last major release of Microsoft Windows to support the Alpha, MIPS or PowerPC CPU architectures. It remained in use by businesses for a number of years, despite Microsoft\'s many efforts to get customers to upgrade to Windows 2000 and newer versions. It was also the last release in the Windows NT family to be branded as Windows NT although Windows 2000 carried the designation "Built on NT Technology".\n\n\n== Features ==\n\nAlthough the chief enhancement has been the addition of the Windows 95 shell, there are several major performance, scalability and feature improvements to the core architecture, kernel, USER32, COM and MSRPC. Windows NT 4.0 also introduced the concept of system policies and the System Policy Editor.\nOther important features were:\nCrypto API\nTelephony API 2.0 with limited Unimodem support, which was the first release of TAPI on Windows NT\nDCOM and new OLE features\nMicrosoft Transaction Server for network applications\nMicrosoft Message Queuing (MSMQ), which improved interprocess communication\nWinsock 2 and the TCP/IP stack improvements\nFile system defragmentation support\nThe server editions of Windows NT 4.0 include Internet Information Services 2.0, Microsoft FrontPage 1.1, NetShow Services, Remote Access Service (which includes a PPTP server for VPN functionality) and Multi-Protocol Routing service. There are new administrative wizards and a lite version of the Network Monitor utility shipped with System Management Server. The Enterprise edition introduced Microsoft Cluster Server.\nOne significant difference from previous versions of Windows NT is that the Graphics Device Interface (GDI) is moved into kernel mode rather than being in user mode in the CSRSS process. This eliminated a process-to-process context switch in calling GDI functions, resulting in a significant performance improvement over Windows NT 3.51, particularly in the graphical user interface. This, however, also mandated that graphics and printer drivers had to run in kernel mode as well, resulting in potential stability issues.\nWindows NT 4.0 was the first release of Microsoft Windows to include DirectX as standard—version 2 shipped with the initial release of Windows NT 4.0, and version 3 was included with the release of Service Pack 3 in mid-1997. Later versions of DirectX were not released for Windows NT 4.0. However, OpenGL was supported; it was used by Quake 3 and Unreal Tournament.\nIn early releases of 4.0, numerous stability issues did occur as graphics and printer vendors had to change their drivers to be compatible with the kernel mode interfaces exported by GDI. The change to move the GDI to run in the same process context as its caller was prompted by complaints from NT Workstation users about real-time graphics performance, but this change put a considerable onus on hardware manufacturers to update device drivers.\nWindows NT 4.0 also included a new Windows Task Manager utility. Previous versions of Windows NT included the Task List utility, but it only shows applications currently on the desktop. To monitor CPU and memory usage, users were forced to use Performance Monitor. The task manager offers a more convenient way of getting a snapshot of all the processes running on the system at any given time.\nInternet Explorer 2 was bundled with Windows NT 4, which updated versions included with each service pack. Service Pack 6, the last service pack for Windows NT 4, included Internet Explorer 5.01.\nWindows NT 4.0 upgraded NTVDM\'s x86 emulation in the RISC versions from 286 to 486. Sysprep was introduced as a deployment tool with Windows NT 4.0.\n\n\n== Comparison with Windows 95 ==\nWhile providing much greater stability than Windows 95, it was less flexible from a desktop perspective. Much of the stability was gained through the use of protected memory and the hardware abstraction layer. Direct hardware access was disallowed and "misbehaving" programs were terminated without needing the computer to be restarted. The trade-off was that NT required much more memory (32 MB for normal desktop use, 128 MB or more for heavy 3D applications) in comparison to consumer targeted products such as Windows 95.\nWhile nearly all programs written for Windows 95 run on Windows NT, many 3D games would not, partly because of limited DirectX support for Windows NT 4.0. Third-party device drivers were an alternative to access the hardware directly, but poorly written drivers became a frequent source of infamous errors known as Blue Screen of Death (BSoD) that would require the system to be restarted.\nIn spite of shipping a year later than Windows 95, by default, there is no Plug and Play support and no Device Manager on Windows NT 4, which greatly simplifies installation of hardware devices (although limited support could be installed later). Many basic DOS programs would run; however, graphical DOS programs would not run because of the way they accessed graphics hardware. Although Windows NT 4.0 introduced an application programming interface (API) for defragmentation, there was no built-in defragmentation utility, unlike Windows 95. Also, Windows NT 4.0 lacked USB support, a preliminary version of which would be added to OEM editions of Windows 95 in OSR 2.1.\nThe difference between the NT family and 9x family would remain until the release of Windows XP in 2001. At that time, the APIs —such as OpenGL and DirectX— had matured sufficiently to be more efficient to write for common PC hardware. On the other hand, the hardware itself had become powerful enough to handle the API processing overhead.\nThe maximum amount of supported physical random-access memory (RAM) in Windows NT 4.0 is 4 GB, which is the maximum possible for a purely 32-bit x86 operating system. By comparison, Windows 95 fails to boot on computers with approximately more than 480 MB of memory.\nLike previous versions of NT, NT 4.0 can run on multiple processor architectures. Windows 95, however, can only run on x86.\n\n\n== Editions ==\n\nWindows NT 4.0 Server was included in versions 4.0 and 4.5 of BackOffice Small Business Server suite.\n\n\n=== Client ===\nWindows NT 4.0 Workstation was designed for use as the general business desktop operating system.\n\n\n=== Servers ===\nWindows NT 4.0 Server, released in 1996, was designed for small-scale business server systems.\nWindows NT 4.0 Server, Enterprise Edition, released in 1997, is the precursor to the Enterprise line of the Windows server family (Advanced Server in Windows 2000). Enterprise Server was designed for high-demand, high-traffic networks. Windows NT 4.0 Server, Enterprise Edition includes Service Pack 3. The Enterprise Edition saw the introduction of the /3GB boot flag, which changed the default virtual address space mapping from 2 GB kernel and 2 GB userland to 1 GB kernel and 3 GB userland. It also introduced a PSE36 driver for mapping up to 64 GB memory (although chipsets of the era supported only up to 8 GB.) This version also sees the first introduction of cluster service.\nWindows NT 4.0 Terminal Server Edition, released in 1998, allows the users to log on remotely. The same functionality was called Terminal Services in Windows 2000 and later server releases, and also powers the Remote Desktop feature that first appeared in Windows XP.\n\n\n=== Embedded ===\nWindows NT 4.0 Embedded (abbreviated NTe) is an edition of Windows NT 4.0 that was aimed at computer-powered major appliances, vending machines, ATMs and other devices that cannot be considered general-purpose computers per se. It is the same system as the standard Windows NT 4.0, but it comes packaged in a database of components and dependencies, from which a developer can choose individual components to build customized setup CDs and hard disk boot images. Windows NT 4.0 Embedded includes Service Pack 5. It was succeeded by Windows XP Embedded.\n\n\n== Upgradeability ==\nAn Option Pack was available as a free-bundled CD starting around 1998, which included IIS 4.0 with Active Server Pages, FrontPage Server Extensions, Certificate Server, MTS, MSMQ, CDONTS, Internet Authentication Service (IAS), Indexing Service, Microsoft Management Console 1.0, Microsoft Site Server, SMTP and NNTP services and other new software.\nSeveral features such as Distributed File System and Windows NT Load Balancing Service (WLBS) were delivered as addons for Windows NT Server 4.0. The Routing and Remote Access Service was also a downloadable feature which replaced Windows NT 4.0\'s separate RAS and Multi-Protocol Routing services.\nThe last version of Microsoft Office to run on Windows NT 4.0 is Office XP.\n\n\n== Service packs ==\nMicrosoft released Windows NT 4.0 service packs primarily to fix bugs. Windows NT 4.0, during its lifecycle, had several service packs, as well as numerous service rollup packages and option packs. Only the first service pack was made available for the MIPS architecture, and Service Park 3 was the final release for the PowerPC architecture. The last full service pack was Service Pack 6a (SP6a).\nService Pack 7 was planned at one stage in early 2001, but this became the Post SP6a Security Rollup and not a full service pack, released on 26 July 2001, 16 months after Windows 2000 and nearly three months prior to Windows XP.\nThe service packs also added a multitude of new features such as newer versions of or improvements to Internet Information Services, public-key and certificate authority functionality, user accounts and user profile improvements, smart card support, improved symmetric multiprocessing (SMP) scalability, clustering capabilities, COM support improvements, User Profile Disk Quotas, Event Log service, Security Configuration Manager MMC snap-in, MS-CHAPv2 and NTLMv2, SMB packet signing, SYSKEY, boot improvements, WINS improvements, Routing and Remote Access Service (RRAS), PPTP, DCOM/HTTP tunneling improvements, IGMPv2, WMI, Active Accessibility and NTFS 3.0 support among others.\n\n\n== Resource Kits ==\nMicrosoft released five revisions of the Windows NT 4.0 Workstation and Server Resource Kit (original release plus four supplements) which contained a large number of tools and utilities, such as desktops.exe which allowed the user to have multiple desktops, as well as third-party software.\n\n\n== Security ==\nMicrosoft stopped providing security updates for Windows NT 4.0 Workstation on 30 June 2004 and Windows NT 4.0 Server on 31 December 2004, due to major security flaws including Microsoft Security Bulletin MS03-010, which according to Microsoft could not be patched without significant changes to the core operating system. According to the security bulletin, "Due to [the] fundamental differences between Windows NT 4.0 and Windows 2000 and its successors, it is infeasible to rebuild the software for Windows NT 4.0 to eliminate the vulnerability. To do so would require re-architecting a very significant amount of the Windows NT 4.0 operating system, and [...] there would be no assurance that applications designed to run on Windows NT 4.0 would continue to operate on the patched system."\nBetween June 2003 and June 2007, 127 security flaws were identified and patched in Windows 2000 Server, many of which may also affect Windows NT 4.0 Server; however, Microsoft does not test security bulletins against unsupported software.\n\n\n== References ==\n\n\n== External links ==\nGuidebook: Windows NT 4.0 Gallery – A website dedicated to preserving and showcasing Graphical User Interfaces\nHPC:Factor Windows NT 4.0 Workstation Patches & Updates Guide\nHPC:Factor Windows NT 4.0 Server Patches & Updates Guide\nJosephn.net: Windows NT 4.0 Terminal Server Edition Tips & Updates\nMDGx: Windows NT 4.0 Essential Free Upgrades + Fixes']
['A Creative Commons (CC) license is one of several public copyright licenses that enable the free distribution of an otherwise copyrighted work. A CC license is used when an author wants to give people the right to share, use, and build upon a work that they have created. CC provides an author flexibility (for example, they might choose to allow only non-commercial uses of their own work) and protects the people who use or redistribute an author\'s work from concerns of copyright infringement as long as they abide by the conditions that are specified in the license by which the author distributes the work.\nThere are several types of CC licenses. The licenses differ by several combinations that condition the terms of distribution. They were initially released on December 16, 2002 by Creative Commons, a U.S. non-profit corporation founded in 2001. There have also been five versions of the suite of licenses, numbered 1.0 through 4.0. As of February 2018, the 4.0 license suite is the most current.\nIn October 2014 the Open Knowledge Foundation approved the Creative Commons CC BY, CC BY-SA and CC0 licenses as conformant with the "Open Definition" for content and data.\n\n\n== Applicable works ==\nWork licensed under a Creative Commons license is governed by applicable copyright law. This allows Creative Commons licenses to be applied to all work falling under copyright, including: books, plays, movies, music, articles, photographs, blogs, and websites. Creative Commons does not recommend the use of Creative Commons licenses for software.\nThere are over 35,000 works that are available in hardcopy and have a registered ISBN number. Creative Commons splits these works into two categories, one of which encompasses self-published books.\nHowever, application of a Creative Commons license may not modify the rights allowed by fair use or fair dealing or exert restrictions which violate copyright exceptions. Furthermore, Creative Commons licenses are non-exclusive and non-revocable. Any work or copies of the work obtained under a Creative Commons license may continue to be used under that license.\nIn the case of works protected by multiple Creative Common licenses, the user may choose either.\n\n\n== Types of licenses ==\n\nThe CC licenses all grant the "baseline rights", such as the right to distribute the copyrighted work worldwide for non-commercial purposes, and without modification. The details of each of these licenses depend on the version, and comprises a selection out of four conditions:\n\nThe last two clauses are not free content licenses, according to definitions such as DFSG or the Free Software Foundation\'s standards, and cannot be used in contexts that require these freedoms, such as Wikipedia. For software, Creative Commons includes three free licenses created by other institutions: the BSD License, the GNU LGPL, and the GNU GPL.\nMixing and matching these conditions produces sixteen possible combinations, of which eleven are valid Creative Commons licenses and five are not. Of the five invalid combinations, four include both the "nd" and "sa" clauses, which are mutually exclusive; and one includes none of the clauses. Of the eleven valid combinations, the five that lack the "by" clause have been retired because 98% of licensors requested attribution, though they do remain available for reference on the website. This leaves six regularly used licenses + the CC0 public domain waiver:\n\n\n=== Seven regularly used licenses ===\n\nFor example, the Creative Commons Attribution (BY) license allows one to share and remix (create derivative works), even for commercial use, so long as attribution is given.\n\n\n== Version 4.0 and international use ==\n\nThe original non-localized Creative Commons licenses were written with the U.S. legal system in mind, therefore the wording may be incompatible with local legislation in other jurisdictions, rendering the licenses unenforceable there. To address this issue, Creative Commons asked its affiliates to translate the various licenses to reflect local laws in a process called "porting." As of July 2011, Creative Commons licenses have been ported to over 50 jurisdictions worldwide.\nThe latest version 4.0 of the Creative Commons licenses, released on November 25, 2013, are generic licenses that are applicable to most jurisdictions and do not usually require ports. No new ports have been implemented in version 4.0 of the license. Version 4.0 discourages using ported versions and instead acts as a single global license.\n\n\n== Rights ==\n\n\n=== Attribution ===\nSince 2004, all current licenses (beside the CC0 waiver) require attribution of the original author, the BY component. The attribution must be given to "the best of [one\'s] ability using the information available". Generally this implies the following:\nInclude any copyright notices (if applicable). If the work itself contains any copyright notices placed there by the copyright holder, those notices must be left intact, or reproduced in a way that is reasonable to the medium in which the work is being re-published.\nCite the author\'s name, screen name, or user ID, etc. If the work is being published on the Internet, it is nice to link that name to the person\'s profile page, if such a page exists.\nCite the work\'s title or name (if applicable), if such a thing exists. If the work is being published on the Internet, it is nice to link the name or title directly to the original work.\nCite the specific CC license the work is under. If the work is being published on the Internet, it is nice if the license citation links to the license on the CC website.\nMention if the work is a derivative work or adaptation. In addition to the above, one needs to identify that their work is a derivative work, e.g., "This is a Finnish translation of [original work] by [author]." or "Screenplay based on [original work] by [author]."\n\n\n=== Non-commercial licenses ===\n\nThe "non-commercial" option included in some Creative Commons licenses is controversial in definition, as it is sometimes unclear what can be considered a non-commercial setting, and application, since its restrictions differ from the principles of open content promoted by other permissive licenses. In 2014 Wikimedia Deutschland published a guide to using Creative Commons licenses as wiki pages for translations and as PDF.\n\n\n=== Zero / public domain ===\n\nBesides licenses, Creative Commons also offers through CC0 a way to release material worldwide into the public domain. CC0 is a legal tool for waiving as many rights as legally possible. Or, when not legally possible, CC0 acts as fallback as public domain equivalent license. Development of CC0 began in 2007 and the tool was released in 2009. A major target of the license was the scientific data community.\nIn 2010, Creative Commons announced its Public Domain Mark, a tool for labeling works already in the public domain. Together, CC0 and the Public Domain Mark replace the Public Domain Dedication and Certification, which took a U.S.-centric approach and co-mingled distinct operations.\nIn 2011, the Free Software Foundation added CC0 to its free software licenses, and currently recommends CC0 as the preferred method of releasing software into the public domain.\nIn February 2012 CC0 was submitted to Open Source Initiative (OSI) for their approval. However, controversy arose over its clause which excluded from the scope of the license any relevant patents held by the copyright holder. This clause was added with scientific data in mind rather than software, but some members of the OSI believed it could weaken users\' defenses against software patents. As a result, Creative Commons withdrew their submission, and the license is not currently approved by the OSI.\nIn 2013, Unsplash began using the CC0 license to distribute free stock photography. It now distributes several million photos a month and has inspired a host of similar sites, including CC0 photography companies and CC0 blogging companies. Lawrence Lessig, the founder of Creative Commons, has contributed to the site. Unsplash moved from using the CC0 licence to their own similar licence in June 2017, but with a restriction added on using the photos to make a competing service which makes it incompatible with the CC0 licence.\nIn October 2014 the Open Knowledge Foundation approved the Creative Commons CC0 as conformant with the "Open Definition" and recommend the license to dedicate content to the public domain.\n\n\n=== Adaptation ===\nRights in an adaptation can be expressed by a CC license that is compatible with the status or licensing of the original work or works on which the adaptation is based.\n\n\n== Legal aspects ==\nThe legal implications of large numbers of works having Creative Commons licensing are difficult to predict, and there is speculation that media creators often lack insight to be able to choose the license which best meets their intent in applying it.\nSome works licensed using Creative Commons licenses have been involved in several court cases. Creative Commons itself was not a party to any of these cases; they only involved licensors or licensees of Creative Commons licenses. When the cases went as far as decisions by judges (that is, they were not dismissed for lack of jurisdiction or were not settled privately out of court), they have all validated the legal robustness of Creative Commons public licenses. Here are some notable cases:\n\n\n=== Dutch tabloid ===\nIn early 2006, podcaster Adam Curry sued a Dutch tabloid who published photos from Curry\'s Flickr page without Curry\'s permission. The photos were licensed under the Creative Commons Non-Commercial license. While the verdict was in favor of Curry, the tabloid avoided having to pay restitution to him as long as they did not repeat the offense. Professor Bernt Hugenholtz, main creator of the Dutch CC license and director of the Institute for Information Law of the University of Amsterdam, commented, "The Dutch Court\'s decision is especially noteworthy because it confirms that the conditions of a Creative Commons license automatically apply to the content licensed under it, and binds users of such content even without expressly agreeing to, or having knowledge of, the conditions of the license."\n\n\n=== Virgin Mobile ===\nIn 2007, Virgin Mobile Australia launched an Australian bus stop ad campaign promoting their cellphone text messaging service using the work of amateur photographers who uploaded their work to Flickr using a Creative Commons-BY (Attribution) license. Users licensing their images this way freed their work for use by any other entity, as long as the original creator was attributed credit, without any other compensation required. Virgin upheld this single restriction by printing a URL leading to the photographer\'s Flickr page on each of their ads. However, one picture, depicting 15-year-old Alison Chang at a fund-raising carwash for her church, caused some controversy when she sued Virgin Mobile. The photo was taken by Alison\'s church youth counselor, Justin Ho-Wee Wong, who uploaded the image to Flickr under the Creative Commons license. In 2008, the case (concerning personality rights rather than copyright as such) was thrown out of a Texas court for lack of jurisdiction.\n\n\n=== SGAE vs Fernández ===\nIn the fall of 2006, the collecting society Sociedad General de Autores y Editores (SGAE) in Spain sued Ricardo Andrés Utrera Fernández, owner of a disco bar located in Badajoz who played CC-licensed music. SGAE argued that Fernández should pay royalties for public performance of the music between November 2002 and August 2005. The Lower Court rejected the collecting society\'s claims because the owner of the bar proved that the music he was using was not managed by the society.\nIn February 2006, the Cultural Association Ladinamo (based in Madrid, and represented by Javier de la Cueva) was granted the use of copyleft music in their public activities. The sentence said: "Admitting the existence of music equipment, a joint evaluation of the evidence practiced, this court is convinced that the defendant prevents communication of works whose management is entrusted to the plaintiff [SGAE], using a repertoire of authors who have not assigned the exploitation of their rights to the SGAE, having at its disposal a database for that purpose and so it is manifested both by the legal representative of the Association and by Manuela Villa Acosta, in charge of the cultural programming of the association, which is compatible with the alternative character of the Association and its integration in the movement called \'copy left\'".\n\n\n=== GateHouse Media, Inc. vs. That\'s Great News, LLC ===\nOn June 30, 2010 GateHouse Media filed a lawsuit against That\'s Great News. GateHouse Media owns a number of local newspapers, including Rockford Register Star, which is based in Rockford, Illinois. That\'s Great News makes plaques out of newspaper articles and sells them to the people featured in the articles. GateHouse sued That\'s Great News for copyright infringement and breach of contract. GateHouse claimed that TGN violated the non-commercial and no-derivative works restrictions on GateHouse Creative Commons licensed work when TGN published the material on its website. The case was settled on August 17, 2010, though the settlement was not made public.\n\n\n=== Drauglis v. Kappa Map Group, LLC ===\nThe plaintiff was photographer Art Drauglis, who uploaded several pictures to the photo-sharing website Flickr using Creative Commons Attribution-ShareAlike 2.0 Generic License (CC BY-SA), including one entitled "Swain\'s Lock, Montgomery Co., MD.". The defendant was Kappa Map Group, a map-making company, which downloaded the image and used it in a compilation entitled "Montgomery Co. Maryland Street Atlas". Though there was nothing on the cover that indicated the origin of the picture, the text "Photo: Swain\'s Lock, Montgomery Co., MD Photographer: Carly Lesser & Art Drauglis, Creative Commoms  [sic], CC-BY-SA-2.0" appeared at the bottom of the back cover.\nThe validity of the CC BY-SA 2.0 as a license was not in dispute. The CC BY-SA 2.0 requires that the licensee to use nothing less restrictive than the CC BY-SA 2.0 terms. The atlas was sold commercially and not for free reuse by others. The dispute was whether Drauglis\' license terms that would apply to "derivative works" applied to the entire atlas. Drauglis sued the defendants on June 2014 for copyright infringement and license breach, seeking declaratory and injunctive relief, damages, fees, and costs. Drauglis asserted, among other things, that Kappa Map Group "exceeded the scope of the License because defendant did not publish the Atlas under a license with the same or similar terms as those under which the Photograph was originally licensed." The judge dismissed the case on that count, ruling that the atlas was not a derivative work of the photograph in the sense of the license, but rather a collective work. Since the atlas was not a derivative work of the photograph, Kappa Map Group did not need to license the entire atlas under the CC BY-SA 2.0 license. The judge also determined that the work had been properly attributed.\nIn particular, the judge determined that it was sufficient to credit the author of the photo as prominently as authors of similar authorship (such as the authors of individual maps contained in the book) and that the name "CC-BY-SA-2.0" is sufficiently precise to locate the correct license on the internet and can be considered a valid URI of the license.\n\n\n=== Verband zum Schutz geistigen Eigentums im Internet (VGSE) ===\nThis incident has not been tested in court, but it highlights a potentially disturbing practice. In July 2016, German computer magazine LinuxUser reports that a German blogger Christoph Langner used two CC-BY licensed photographs from Berlin photographer Dennis Skley on his private blog Linuxundich.de. Langner duly mentioned the author and the license and added a link to the original. Langner was later contacted by the Verband zum Schutz geistigen Eigentums im Internet (VGSE) (Association for the Protection of Intellectual Property in the Internet) with a demand for €2300 for failing to provide the full name of the work, the full name of the author, the license text, and a source link, as is apparently required by the fine print in the license. Of this sum, €40 goes to the photographer and remainder is retained by VGSE.\n\n\n== Works with a Creative Commons license ==\n\nCreative Commons maintains a content directory wiki of organizations and projects using Creative Commons licenses. On its website CC also provides case studies of projects using CC licenses across the world. CC licensed content can also be accessed through a number of content directories and search engines (see CC licensed content directories).\n\n\n== Retired licenses ==\nDue to either disuse or criticism, a number of previously offered Creative Commons licenses have since been retired, and are no longer recommended for new works. The retired licenses include all licenses lacking the Attribution element other than CC0, as well as the following four licenses:\nDeveloping Nations License: a license which only applies to developing countries deemed to be "non-high-income economies" by the World Bank. Full copyright restrictions apply to people in other countries.\nSampling: parts of the work can be used for any purpose other than advertising, but the whole work cannot be copied or modified\nSampling Plus: parts of the work can be copied and modified for any purpose other than advertising, and the entire work can be copied for noncommercial purposes\nNonCommercial Sampling Plus: the whole work or parts of the work can be copied and modified for non-commercial purposes\n\n\n== See also ==\n\nFree culture movement\nFree music\nFree software\nNon-commercial educational\n\n\n== References ==\n\n\n== External links ==\nOfficial website\nFull selection of licenses\nLicenses. Overview of free licenses. freedomdefined.org']
